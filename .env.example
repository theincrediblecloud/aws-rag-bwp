# runtime config
APP_ENV=local
ARTIFACTS_BUCKET=""
MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
INDEX_PREFIX=rag/index
INDEX_DIR=$(PWD)/store_local
INDEX_PATH=$(PWD)/store_local/vectors.npy 
META_PATH=$(PWD)/store_local/meta.jsonl
SLACK_SIGNING_SECRET_ARN=""
SLACK_BOT_TOKEN_ARN=""
TOP_K=24
RETRIEVE_K=24
CONTEXT_K=8
ANSWER_FALLBACK=allow
FALLBACK_MIN_SCORE=0.32
FALLBACK_MESSAGE="I couldn’t find an in-corpus basis. Here’s a brief general answer (no citations)."
STRICT_MESSAGE="I’m sorry, I can’t provide an answer based on the available documents."
AWS_REGION=us-east-1
EMBED_PROVIDER=local
BEDROCK_REGION=us-east-1
BEDROCK_MODEL=amazon.titan-embed-text-v2:0
LLM_PROVIDER=local
LLM_MODEL_ID=arn:aws:bedrock:us-east-1:471112701253:inference-profile/us.anthropic.claude-haiku-4-5-20251001-v1:0
LLM_INFERENCE_PROFILE_ARN=arn:aws:bedrock:us-east-1:471112701253:inference-profile/us.anthropic.claude-haiku-4-5-20251001-v1:0
MAX_TOKENS=500
TEMPERATURE=0.2
INDEX_VERSION=v2
CACHE_TIER1=true
CACHE_TTL_SEC=1800
CACHE_MAX_ITEMS=1000
CACHE_ANSWERS=false
DDB_CACHE_TABLE=rag-answer-cache
CACHE_TTL_SECONDS=172800
EMBED_DIM=384
CHUNK_SIZE=600
SNIPPET_CHARS=800
CHUNK_OVERLAP=50