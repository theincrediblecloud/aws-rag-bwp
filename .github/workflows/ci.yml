name: CI
on:
  pull_request:
    branches: [ main ]
  push:
    branches-ignore: [ main ]

jobs:
  ci:
    runs-on: ubuntu-latest
    env:
      PYTHONPATH: src
      # keep local embeddings for CI speed/stability
      EMBED_PROVIDER: local
      EMBED_MODEL: sentence-transformers/all-MiniLM-L6-v2
      INDEX_DIR: store
      INDEX_PATH: store/vectors.npy
      META_PATH: store/meta.jsonl
      CHUNK_SIZE: "600"
      CHUNK_OVERLAP: "80"
      TOP_K: "8"
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }
      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt
          # test-only deps
          pip install ruff mypy pytest sentence-transformers torch pypdf python-docx

      - name: Lint & type
        run: |
          ruff check src
          mypy src || true  # flip to strict once clean

      - name: Unit tests
        run: pytest -q

      - name: Build tiny index (fixture corpus)
        run: |
          mkdir -p data/collections/fixture
          printf "RAG retrieves context for LLMs.\n" > data/collections/fixture/intro.md
          python -m rag.ingest.pipeline --data-dir data/collections/fixture --fresh
          python - <<'PY'
          import numpy as np, os
          V = np.load("store/vectors.npy"); d=V.shape[1]
          assert V.shape[0] > 0 and d in (384,1024), f"bad vectors shape {V.shape}"
          print("OK vectors:", V.shape)
          PY

      - name: Golden-set (fast)
        run: |
          # spin local API
          uvicorn rag.api.app:app --app-dir src --port 8001 --workers 1 & echo $! > uv.pid
          sleep 2
          python golden/eval_golden.py --api http://127.0.0.1:8001/chat golden/fast.jsonl -v
          kill $(cat uv.pid)
